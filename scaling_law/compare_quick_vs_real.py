"""
å¿«é€Ÿç‰ˆ vs çœŸå®ç‰ˆå¯¹æ¯”åˆ†æ
========================

å¯¹æ¯”æ¨¡æ‹Ÿæ•°æ®å’Œå®é™…è®­ç»ƒç»“æœï¼ŒéªŒè¯ï¼š
1. æ¨¡æ‹Ÿæ•°æ®çš„å‡†ç¡®æ€§
2. æ—©åœå¤–æ¨çš„å¯é æ€§
3. Scaling Law çš„é¢„æµ‹èƒ½åŠ›

ä½œè€…: peixingxin
æ—¥æœŸ: 2025-12-29
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
from pathlib import Path

# ============================================================================
# åŠ è½½æ•°æ®
# ============================================================================

def load_quick_results():
    """åŠ è½½å¿«é€Ÿç‰ˆç»“æœï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰"""
    path = Path('scaling_demo/results.json')
    if not path.exists():
        print("âŒ å¿«é€Ÿç‰ˆç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ: python quick_scaling_demo.py")
        return None
    
    with open(path) as f:
        data = json.load(f)
    
    # è½¬æ¢ key ä¸º float
    param_scaling = {float(k): v for k, v in data['param_scaling'].items()}
    data_scaling = {float(k): v for k, v in data['data_scaling'].items()}
    
    return {
        'param_scaling': param_scaling,
        'data_scaling': data_scaling,
        'source': 'quick (æ¨¡æ‹Ÿ)'
    }


def load_real_results(mode='standard'):
    """åŠ è½½çœŸå®ç‰ˆç»“æœï¼ˆå®é™…è®­ç»ƒï¼‰"""
    # å°è¯•ä¸åŒçš„ç»“æœæ–‡ä»¶
    possible_paths = [
        f'./scaling_results_{mode}/results.json',
        './scaling_results_quick/results.json',
        './scaling_results_standard/results.json',
    ]
    
    for path_str in possible_paths:
        path = Path(path_str)
        if path.exists():
            print(f"âœ… æ‰¾åˆ°çœŸå®å®éªŒç»“æœ: {path}")
            with open(path) as f:
                data = json.load(f)
            
            # è½¬æ¢ key ä¸º float
            param_scaling = {float(k): v for k, v in data['param_scaling'].items()}
            data_scaling = {float(k): v for k, v in data['data_scaling'].items()}
            
            return {
                'param_scaling': param_scaling,
                'data_scaling': data_scaling,
                'source': f'real ({mode})'
            }
    
    print("âŒ çœŸå®å®éªŒç»“æœä¸å­˜åœ¨")
    print("è¯·å…ˆè¿è¡Œ: python run_scaling_experiments.py --mode standard")
    return None


# ============================================================================
# å¯¹æ¯”åˆ†æ
# ============================================================================

def compare_results(quick_data, real_data):
    """å¯¹æ¯”å¿«é€Ÿç‰ˆå’ŒçœŸå®ç‰ˆç»“æœ"""
    
    print("\n" + "=" * 80)
    print("ğŸ“Š å¿«é€Ÿç‰ˆ vs çœŸå®ç‰ˆå¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    # å‚æ•° Scaling å¯¹æ¯”
    print("\nã€å‚æ•° Scaling å¯¹æ¯”ã€‘")
    print("-" * 80)
    print(f"{'æ¨¡å‹è§„æ¨¡':>12s} | {'å¿«é€Ÿç‰ˆ Loss':>12s} | {'çœŸå®ç‰ˆ Loss':>12s} | {'è¯¯å·®':>10s} | {'ç›¸å¯¹è¯¯å·®':>10s}")
    print("-" * 80)
    
    param_errors = []
    for n in sorted(quick_data['param_scaling'].keys()):
        if n in real_data['param_scaling']:
            quick_loss = quick_data['param_scaling'][n]
            real_loss = real_data['param_scaling'][n]
            error = abs(quick_loss - real_loss)
            rel_error = error / real_loss * 100
            param_errors.append(rel_error)
            
            print(f"{n/1e6:10.1f}M | {quick_loss:12.4f} | {real_loss:12.4f} | "
                  f"{error:10.4f} | {rel_error:9.2f}%")
    
    avg_param_error = np.mean(param_errors) if param_errors else 0
    print("-" * 80)
    print(f"{'å¹³å‡ç›¸å¯¹è¯¯å·®':>47s} | {avg_param_error:9.2f}%")
    
    # æ•°æ® Scaling å¯¹æ¯”
    print("\nã€æ•°æ® Scaling å¯¹æ¯”ã€‘")
    print("-" * 80)
    print(f"{'æ•°æ®è§„æ¨¡':>12s} | {'å¿«é€Ÿç‰ˆ Loss':>12s} | {'çœŸå®ç‰ˆ Loss':>12s} | {'è¯¯å·®':>10s} | {'ç›¸å¯¹è¯¯å·®':>10s}")
    print("-" * 80)
    
    data_errors = []
    for d in sorted(quick_data['data_scaling'].keys()):
        if d in real_data['data_scaling']:
            quick_loss = quick_data['data_scaling'][d]
            real_loss = real_data['data_scaling'][d]
            error = abs(quick_loss - real_loss)
            rel_error = error / real_loss * 100
            data_errors.append(rel_error)
            
            if d >= 1e9:
                d_str = f"{d/1e9:.1f}B"
            else:
                d_str = f"{d/1e6:.0f}M"
            
            print(f"{d_str:>12s} | {quick_loss:12.4f} | {real_loss:12.4f} | "
                  f"{error:10.4f} | {rel_error:9.2f}%")
    
    avg_data_error = np.mean(data_errors) if data_errors else 0
    print("-" * 80)
    print(f"{'å¹³å‡ç›¸å¯¹è¯¯å·®':>47s} | {avg_data_error:9.2f}%")
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“ˆ æ€»ç»“")
    print("=" * 80)
    print(f"å‚æ•° Scaling å¹³å‡è¯¯å·®: {avg_param_error:.2f}%")
    print(f"æ•°æ® Scaling å¹³å‡è¯¯å·®: {avg_data_error:.2f}%")
    print(f"æ€»ä½“å¹³å‡è¯¯å·®: {(avg_param_error + avg_data_error) / 2:.2f}%")
    
    if (avg_param_error + avg_data_error) / 2 < 5:
        print("\nâœ… å¿«é€Ÿç‰ˆé¢„æµ‹éå¸¸å‡†ç¡®ï¼è¯¯å·® < 5%")
    elif (avg_param_error + avg_data_error) / 2 < 10:
        print("\nâœ… å¿«é€Ÿç‰ˆé¢„æµ‹è¾ƒå‡†ç¡®ï¼Œè¯¯å·® < 10%")
    else:
        print("\nâš ï¸  å¿«é€Ÿç‰ˆé¢„æµ‹å­˜åœ¨ä¸€å®šåå·®ï¼Œå»ºè®®è°ƒæ•´æ¨¡æ‹Ÿå‚æ•°")
    
    return param_errors, data_errors


# ============================================================================
# å¯è§†åŒ–å¯¹æ¯”
# ============================================================================

def plot_comparison(quick_data, real_data, save_dir='./comparison_results'):
    """ç”Ÿæˆå¯¹æ¯”å›¾è¡¨"""
    
    Path(save_dir).mkdir(parents=True, exist_ok=True)
    
    fig, axes = plt.subplots(2, 2, figsize=(18, 14))
    
    # ========== å›¾ 1: å‚æ•° Scaling å¯¹æ¯” ==========
    ax1 = axes[0, 0]
    
    # å¿«é€Ÿç‰ˆæ•°æ®
    quick_params = np.array(sorted(quick_data['param_scaling'].keys()))
    quick_param_losses = np.array([quick_data['param_scaling'][n] for n in quick_params])
    
    # çœŸå®ç‰ˆæ•°æ®
    real_params = np.array(sorted(real_data['param_scaling'].keys()))
    real_param_losses = np.array([real_data['param_scaling'][n] for n in real_params])
    
    ax1.loglog(quick_params, quick_param_losses, 'o-', markersize=10, linewidth=2,
              label='å¿«é€Ÿç‰ˆ (æ¨¡æ‹Ÿ)', color='#3b82f6', alpha=0.7)
    ax1.loglog(real_params, real_param_losses, 's--', markersize=10, linewidth=2,
              label='çœŸå®ç‰ˆ (è®­ç»ƒ)', color='#ef4444', alpha=0.7)
    
    ax1.set_xlabel('Parameters (N)', fontsize=13, fontweight='bold')
    ax1.set_ylabel('Loss (L)', fontsize=13, fontweight='bold')
    ax1.set_title('å‚æ•° Scaling: å¿«é€Ÿç‰ˆ vs çœŸå®ç‰ˆ', fontsize=15, fontweight='bold')
    ax1.grid(True, alpha=0.3, which='both')
    ax1.legend(fontsize=12)
    
    # ========== å›¾ 2: æ•°æ® Scaling å¯¹æ¯” ==========
    ax2 = axes[0, 1]
    
    # å¿«é€Ÿç‰ˆæ•°æ®
    quick_tokens = np.array(sorted(quick_data['data_scaling'].keys()))
    quick_data_losses = np.array([quick_data['data_scaling'][d] for d in quick_tokens])
    
    # çœŸå®ç‰ˆæ•°æ®
    real_tokens = np.array(sorted(real_data['data_scaling'].keys()))
    real_data_losses = np.array([real_data['data_scaling'][d] for d in real_tokens])
    
    ax2.loglog(quick_tokens, quick_data_losses, 'o-', markersize=10, linewidth=2,
              label='å¿«é€Ÿç‰ˆ (æ¨¡æ‹Ÿ)', color='#3b82f6', alpha=0.7)
    ax2.loglog(real_tokens, real_data_losses, 's--', markersize=10, linewidth=2,
              label='çœŸå®ç‰ˆ (è®­ç»ƒ)', color='#ef4444', alpha=0.7)
    
    ax2.set_xlabel('Dataset Size (D, tokens)', fontsize=13, fontweight='bold')
    ax2.set_ylabel('Loss (L)', fontsize=13, fontweight='bold')
    ax2.set_title('æ•°æ® Scaling: å¿«é€Ÿç‰ˆ vs çœŸå®ç‰ˆ', fontsize=15, fontweight='bold')
    ax2.grid(True, alpha=0.3, which='both')
    ax2.legend(fontsize=12)
    
    # ========== å›¾ 3: å‚æ•° Scaling è¯¯å·®åˆ†æ ==========
    ax3 = axes[1, 0]
    
    # è®¡ç®—é‡å çš„ç‚¹
    common_params = sorted(set(quick_params) & set(real_params))
    if common_params:
        errors = []
        for n in common_params:
            quick_loss = quick_data['param_scaling'][n]
            real_loss = real_data['param_scaling'][n]
            rel_error = abs(quick_loss - real_loss) / real_loss * 100
            errors.append(rel_error)
        
        ax3.semilogx(common_params, errors, 'o-', markersize=10, linewidth=2,
                    color='#10b981', markeredgewidth=2, markeredgecolor='white')
        ax3.axhline(y=5, color='#f59e0b', linestyle='--', linewidth=2, label='5% è¯¯å·®çº¿')
        ax3.axhline(y=10, color='#ef4444', linestyle='--', linewidth=2, label='10% è¯¯å·®çº¿')
        
        ax3.set_xlabel('Parameters (N)', fontsize=13, fontweight='bold')
        ax3.set_ylabel('ç›¸å¯¹è¯¯å·® (%)', fontsize=13, fontweight='bold')
        ax3.set_title('å‚æ•° Scaling è¯¯å·®åˆ†æ', fontsize=15, fontweight='bold')
        ax3.grid(True, alpha=0.3)
        ax3.legend(fontsize=11)
    
    # ========== å›¾ 4: æ•°æ® Scaling è¯¯å·®åˆ†æ ==========
    ax4 = axes[1, 1]
    
    # è®¡ç®—é‡å çš„ç‚¹
    common_tokens = sorted(set(quick_tokens) & set(real_tokens))
    if common_tokens:
        errors = []
        for d in common_tokens:
            quick_loss = quick_data['data_scaling'][d]
            real_loss = real_data['data_scaling'][d]
            rel_error = abs(quick_loss - real_loss) / real_loss * 100
            errors.append(rel_error)
        
        ax4.semilogx(common_tokens, errors, 's-', markersize=10, linewidth=2,
                    color='#10b981', markeredgewidth=2, markeredgecolor='white')
        ax4.axhline(y=5, color='#f59e0b', linestyle='--', linewidth=2, label='5% è¯¯å·®çº¿')
        ax4.axhline(y=10, color='#ef4444', linestyle='--', linewidth=2, label='10% è¯¯å·®çº¿')
        
        ax4.set_xlabel('Dataset Size (D, tokens)', fontsize=13, fontweight='bold')
        ax4.set_ylabel('ç›¸å¯¹è¯¯å·® (%)', fontsize=13, fontweight='bold')
        ax4.set_title('æ•°æ® Scaling è¯¯å·®åˆ†æ', fontsize=15, fontweight='bold')
        ax4.grid(True, alpha=0.3)
        ax4.legend(fontsize=11)
    
    plt.suptitle('å¿«é€Ÿç‰ˆ vs çœŸå®ç‰ˆ å®Œæ•´å¯¹æ¯”', fontsize=18, fontweight='bold', y=0.995)
    plt.tight_layout()
    
    save_path = Path(save_dir) / 'quick_vs_real_comparison.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"\nâœ… å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: {save_path}")
    plt.close()


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    
    print("=" * 80)
    print("ğŸ”¬ å¿«é€Ÿç‰ˆ vs çœŸå®ç‰ˆå¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½å®éªŒæ•°æ®...")
    quick_data = load_quick_results()
    
    if quick_data is None:
        return
    
    real_data = load_real_results('standard')
    
    if real_data is None:
        # å°è¯•å…¶ä»–æ¨¡å¼
        real_data = load_real_results('quick')
        if real_data is None:
            print("\nâŒ æ— æ³•æ‰¾åˆ°çœŸå®å®éªŒç»“æœ")
            print("\nè¯·å…ˆè¿è¡ŒçœŸå®å®éªŒï¼š")
            print("  python run_scaling_experiments.py --mode quick")
            print("æˆ–è€…ï¼š")
            print("  python run_scaling_experiments.py --mode standard")
            return
    
    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ")
    print(f"  å¿«é€Ÿç‰ˆ: {len(quick_data['param_scaling'])} ä¸ªå‚æ•°ç‚¹, "
          f"{len(quick_data['data_scaling'])} ä¸ªæ•°æ®ç‚¹")
    print(f"  çœŸå®ç‰ˆ: {len(real_data['param_scaling'])} ä¸ªå‚æ•°ç‚¹, "
          f"{len(real_data['data_scaling'])} ä¸ªæ•°æ®ç‚¹")
    
    # å¯¹æ¯”åˆ†æ
    param_errors, data_errors = compare_results(quick_data, real_data)
    
    # å¯è§†åŒ–
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ç”Ÿæˆå¯¹æ¯”å›¾è¡¨")
    print("=" * 80)
    plot_comparison(quick_data, real_data)
    
    # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
    save_dir = Path('./comparison_results')
    save_dir.mkdir(parents=True, exist_ok=True)
    
    report = {
        'quick_source': quick_data['source'],
        'real_source': real_data['source'],
        'param_scaling': {
            'avg_error': float(np.mean(param_errors)) if param_errors else 0,
            'max_error': float(np.max(param_errors)) if param_errors else 0,
            'min_error': float(np.min(param_errors)) if param_errors else 0,
        },
        'data_scaling': {
            'avg_error': float(np.mean(data_errors)) if data_errors else 0,
            'max_error': float(np.max(data_errors)) if data_errors else 0,
            'min_error': float(np.min(data_errors)) if data_errors else 0,
        },
        'overall': {
            'avg_error': float((np.mean(param_errors) + np.mean(data_errors)) / 2) 
                        if param_errors and data_errors else 0
        }
    }
    
    report_path = save_dir / 'comparison_report.json'
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"\nğŸ’¾ å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    print("\n" + "=" * 80)
    print("âœ… å¯¹æ¯”åˆ†æå®Œæˆï¼")
    print("=" * 80)
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - {save_dir}/quick_vs_real_comparison.png")
    print(f"  - {save_dir}/comparison_report.json")


if __name__ == '__main__':
    main()
