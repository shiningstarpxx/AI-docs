# Tasks: Decision Transformer 研究

## 1. 论文研读
- [ ] 1.1 阅读 Decision Transformer 原论文 (Chen et al., 2021)
- [ ] 1.2 理解 Return-Conditioned 序列建模的核心思想
- [ ] 1.3 对比与传统 RL (TD Learning) 的差异

## 2. 核心机制分析
- [ ] 2.1 GPT 架构如何适配 RL 问题
- [ ] 2.2 Return-to-go 条件化的数学形式
- [ ] 2.3 为什么不需要 Bellman 方程和 TD 误差
- [ ] 2.4 离线 RL 场景的优势分析

## 3. 对比分析
- [ ] 3.1 World Models vs Decision Transformer 架构对比
- [ ] 3.2 "学习世界" vs "学习最优轨迹" 的哲学差异
- [ ] 3.3 样本效率和泛化能力对比

## 4. 后续工作梳理
- [ ] 4.1 Trajectory Transformer (Janner et al.)
- [ ] 4.2 Gato: 通用智能体
- [ ] 4.3 RT-2: 视觉-语言-动作模型

## 5. 文档输出
- [ ] 5.1 创建 `14_decision_transformer.md` 深度解析文档
- [ ] 5.2 更新分享 PPT 添加相关内容
