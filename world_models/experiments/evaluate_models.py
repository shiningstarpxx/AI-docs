"""
è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
================
åœ¨æ— æ¢ç´¢æ¨¡å¼ä¸‹æµ‹è¯•çœŸå®æ€§èƒ½
"""

import torch
import gymnasium as gym
import numpy as np
import json
from pathlib import Path


def evaluate_dqn(model_path, num_episodes=10):
    """è¯„ä¼° DQN æ¨¡å‹"""
    import torch.nn as nn
    
    class DQN(nn.Module):
        def __init__(self, state_dim=4, action_dim=2, hidden_size=256):
            super().__init__()
            self.network = nn.Sequential(
                nn.Linear(state_dim, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, action_dim)
            )
        
        def forward(self, state):
            return self.network(state)
    
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    model = DQN().to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    
    env = gym.make("CartPole-v1")
    rewards = []
    
    for ep in range(num_episodes):
        state, _ = env.reset()
        episode_reward = 0
        
        for step in range(500):
            with torch.no_grad():
                state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)
                q_values = model(state_tensor)
                action = q_values.argmax(1).item()
            
            state, reward, terminated, truncated, _ = env.step(action)
            episode_reward += reward
            
            if terminated or truncated:
                break
        
        rewards.append(episode_reward)
        print(f"  Episode {ep+1}/{ num_episodes}: {episode_reward:.1f}")
    
    env.close()
    
    return {
        "mean": np.mean(rewards),
        "std": np.std(rewards),
        "min": np.min(rewards),
        "max": np.max(rewards),
        "all": rewards
    }


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¯ è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆæ— æ¢ç´¢æ¨¡å¼ï¼‰")
    print("=" * 60)
    print()
    
    results = {}
    
    # è¯„ä¼° DQN
    dqn_model_path = Path("./results_dqn/model_final.pth")
    if dqn_model_path.exists():
        print("ğŸ“Š è¯„ä¼° DQN...")
        dqn_results = evaluate_dqn(dqn_model_path, num_episodes=20)
        results["dqn"] = dqn_results
        print(f"  âœ“ DQN å¹³å‡å¥–åŠ±: {dqn_results['mean']:.1f} Â± {dqn_results['std']:.1f}")
        print(f"    èŒƒå›´: [{dqn_results['min']:.0f}, {dqn_results['max']:.0f}]")
        print()
    else:
        print("  âš ï¸ DQN æ¨¡å‹æœªæ‰¾åˆ°")
        print()
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    if results:
        with open("evaluation_results.json", "w") as f:
            json.dump(results, f, indent=2)
        
        print("=" * 60)
        print("âœ… è¯„ä¼°å®Œæˆï¼")
        print("=" * 60)
        print()
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜: evaluation_results.json")
        print()
        
        # æ€»ç»“
        print("ğŸ“Š æ€§èƒ½æ€»ç»“:")
        for method, res in results.items():
            print(f"  {method.upper()}: {res['mean']:.1f} Â± {res['std']:.1f}")
        print()


if __name__ == "__main__":
    main()
