"""
ç”Ÿæˆæ¨¡æ‹Ÿå®éªŒæ•°æ®ç”¨äºæ¼”ç¤ºå¯¹æ¯”
================================
"""

import json
import numpy as np
import os

# è®¾ç½®éšæœºç§å­
np.random.seed(42)

def generate_dqn_data():
    """ç”Ÿæˆ DQN æ¨¡æ‹Ÿæ•°æ®"""
    episodes = 500
    
    # DQN: è¾ƒæ…¢æ”¶æ•›ï¼Œæ ·æœ¬æ•ˆç‡ä½
    episode_rewards = []
    episode_lengths = []
    
    for i in range(episodes):
        # é€æ­¥æå‡ï¼ŒåŠ å…¥å™ªå£°
        base_reward = min(500, 50 + i * 0.9)
        noise = np.random.normal(0, 50)
        reward = max(10, base_reward + noise)
        episode_rewards.append(reward)
        
        # Episode é•¿åº¦
        length = int(min(500, reward))
        episode_lengths.append(length)
    
    loss_history = np.random.exponential(0.1, 10000).tolist()
    
    data = {
        "episode_rewards": episode_rewards,
        "episode_lengths": episode_lengths,
        "loss_history": loss_history,
        "total_steps": sum(episode_lengths)
    }
    
    return data


def generate_simple_wm_data():
    """ç”Ÿæˆ Simple World Model æ¨¡æ‹Ÿæ•°æ®"""
    
    # æ•°æ®æ”¶é›†é˜¶æ®µï¼ˆéšæœºç­–ç•¥ï¼‰
    data_collection_rewards = []
    for i in range(100):
        reward = np.random.uniform(20, 150)
        data_collection_rewards.append(reward)
    
    # ä¸–ç•Œæ¨¡å‹è®­ç»ƒæŸå¤±
    world_model_losses = []
    for i in range(50):
        loss = 2.0 * np.exp(-i * 0.05) + np.random.normal(0, 0.1)
        world_model_losses.append(max(0.01, loss))
    
    # ç­–ç•¥è¿›åŒ–é€‚åº”åº¦ï¼ˆåœ¨æ¢¦å¢ƒä¸­ï¼‰
    policy_fitness = []
    for i in range(100):
        fitness = min(500, 100 + i * 4.0 + np.random.normal(0, 30))
        policy_fitness.append(fitness)
    
    # æœ€ç»ˆçœŸå®ç¯å¢ƒè¯„ä¼°
    evaluation_rewards = [480]
    
    data = {
        "data_collection_rewards": data_collection_rewards,
        "world_model_losses": world_model_losses,
        "policy_fitness": policy_fitness,
        "evaluation_rewards": evaluation_rewards
    }
    
    return data


def generate_mini_dreamer_data():
    """ç”Ÿæˆ Mini Dreamer æ¨¡æ‹Ÿæ•°æ®"""
    episodes = 300
    
    # Mini Dreamer: å¿«é€Ÿæ”¶æ•›ï¼Œæ ·æœ¬æ•ˆç‡é«˜
    episode_rewards = []
    
    for i in range(episodes):
        # å¿«é€Ÿæå‡
        base_reward = min(500, 100 + i * 1.5)
        noise = np.random.normal(0, 30)
        reward = max(20, base_reward + noise)
        episode_rewards.append(reward)
    
    # ä¸–ç•Œæ¨¡å‹æŸå¤±
    world_model_losses = []
    for i in range(1500):
        loss = 1.5 * np.exp(-i * 0.003) + np.random.normal(0, 0.05)
        world_model_losses.append(max(0.01, loss))
    
    # Actor æŸå¤±
    actor_losses = []
    for i in range(1500):
        loss = -5.0 + i * 0.01 + np.random.normal(0, 1.0)
        actor_losses.append(loss)
    
    # Critic æŸå¤±
    critic_losses = []
    for i in range(1500):
        loss = 10.0 * np.exp(-i * 0.002) + np.random.normal(0, 0.5)
        critic_losses.append(max(0.1, loss))
    
    data = {
        "episode_rewards": episode_rewards,
        "world_model_losses": world_model_losses,
        "actor_losses": actor_losses,
        "critic_losses": critic_losses
    }
    
    return data


def main():
    """ç”Ÿæˆæ‰€æœ‰æ¨¡æ‹Ÿæ•°æ®"""
    print("ğŸ² ç”Ÿæˆæ¨¡æ‹Ÿå®éªŒæ•°æ®...")
    print("-" * 50)
    
    # åˆ›å»ºç›®å½•
    os.makedirs("./results_dqn", exist_ok=True)
    os.makedirs("./results_simple_wm", exist_ok=True)
    os.makedirs("./results_mini_dreamer", exist_ok=True)
    
    # ç”Ÿæˆ DQN æ•°æ®
    print("ğŸ“Š ç”Ÿæˆ DQN æ•°æ®...")
    dqn_data = generate_dqn_data()
    with open("./results_dqn/training_data.json", "w") as f:
        json.dump(dqn_data, f, indent=2)
    print(f"   - Episodes: {len(dqn_data['episode_rewards'])}")
    print(f"   - Total Steps: {dqn_data['total_steps']:,}")
    print(f"   - Final Reward: {np.mean(dqn_data['episode_rewards'][-10:]):.1f}")
    
    # ç”Ÿæˆ Simple WM æ•°æ®
    print("\nğŸ“Š ç”Ÿæˆ Simple World Model æ•°æ®...")
    swm_data = generate_simple_wm_data()
    with open("./results_simple_wm/training_history.json", "w") as f:
        json.dump(swm_data, f, indent=2)
    print(f"   - Data Collection: {len(swm_data['data_collection_rewards'])} episodes")
    print(f"   - Policy Generations: {len(swm_data['policy_fitness'])}")
    print(f"   - Final Eval: {swm_data['evaluation_rewards'][0]:.1f}")
    
    # ç”Ÿæˆ Mini Dreamer æ•°æ®
    print("\nğŸ“Š ç”Ÿæˆ Mini Dreamer æ•°æ®...")
    dreamer_data = generate_mini_dreamer_data()
    with open("./results_mini_dreamer/training_data.json", "w") as f:
        json.dump(dreamer_data, f, indent=2)
    print(f"   - Episodes: {len(dreamer_data['episode_rewards'])}")
    print(f"   - Final Reward: {np.mean(dreamer_data['episode_rewards'][-10:]):.1f}")
    
    print("\nâœ… æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("\nç°åœ¨å¯ä»¥è¿è¡Œ: python3 compare_results.py")


if __name__ == "__main__":
    main()
