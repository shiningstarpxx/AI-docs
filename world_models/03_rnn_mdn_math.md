# RNN 与 MDN 数学原理：时序预测的核心

> 通过苏格拉底式对话，深入理解 World Models 中的 M (Memory) 组件

---

## 1. 核心问题：为什么需要 RNN？

### 1.1 MLP 的局限：马尔可夫假设

**简单方案**：用 MLP 预测下一状态

```
z_{t+1} = MLP(z_t, a_t)
```

**隐含假设**（马尔可夫性）：

```
未来只取决于当前: P(z_{t+1} | z_t, a_t)

"只看当前帧就能预测下一帧"
```

### 1.2 马尔可夫假设的失败案例

```
一个球在画面中央:

  帧t:    O     <- 球在这里

问题: 下一帧球在哪？

可能1:   O ->   (向右飞)
可能2:   <- O   (向左飞)
可能3:   O      (静止)
          |
          v     (向下落)

单帧无法判断！
```

**必须看历史**：

```
帧t-2:  O
帧t-1:    O
帧t:        O

现在能判断了: 球在向右飞

帧t+1:          O
```

---

## 2. RNN 的解决方案

### 2.1 引入隐藏状态

```
h_t = f(h_{t-1}, z_t, a_t)

其中:
  h_t = 隐藏状态 (记忆)
  z_t = 当前观测
  a_t = 当前动作
```

### 2.2 隐藏状态的本质

```
h_t = "截至 t 时刻的所有历史信息的压缩"

h_t 编码了:
  - 物体从哪里来 (轨迹)
  - 物体的速度 (位置变化率)
  - 之前发生过什么 (上下文)
```

**类比**：

```
MLP:  只看当前照片，判断接下来发生什么
RNN:  看完整部电影到现在，判断接下来发生什么
      h = "之前剧情的记忆"
```

### 2.3 LSTM: 更好的记忆机制

普通 RNN 有**梯度消失**问题，难以记住长期历史。

LSTM (Long Short-Term Memory) 通过**门控机制**解决：

```
+------------------------------------------+
|                 LSTM                     |
+------------------------------------------+
|                                          |
|  遗忘门 f_t: 决定丢弃哪些旧记忆            |
|  输入门 i_t: 决定接收哪些新信息            |
|  输出门 o_t: 决定输出哪些信息              |
|                                          |
|  c_t = f_t * c_{t-1} + i_t * tanh(...)  |
|        ^^^^^^^^^^^^   ^^^^^^^^^^^^^^^    |
|        保留旧记忆      添加新记忆          |
|                                          |
|  h_t = o_t * tanh(c_t)                   |
|                                          |
+------------------------------------------+
```

---

## 3. 为什么需要 MDN？

### 3.1 环境的随机性

```
例子: 赛车游戏

状态: 你的车在直道上
动作: 踩油门

下一帧可能:
  - 90% 概率: 正常加速
  - 5% 概率: 前方出现障碍物
  - 3% 概率: 对手超车
  - 2% 概率: 下雨了

同样的 (z_t, a_t) -> 多种可能的 z_{t+1}
```

### 3.2 确定性预测的问题

**如果用确定值预测**：

```
预测: z_{t+1} = 某个固定值

问题: 网络会输出"平均值"
      像多张照片叠加的效果——模糊、不真实
```

**如果用分布预测**：

```
预测: P(z_{t+1}) = 混合高斯分布

可以表达: "90%在这里，5%在那里，5%在别处"
采样时能得到清晰、多样的预测
```

---

## 4. MDN (Mixture Density Network)

### 4.1 混合高斯分布

```
P(z) = Σ π_i * N(μ_i, σ_i²)
       i=1..K

其中:
  K = 高斯分量的数量
  π_i = 第 i 个分量的权重 (Σπ_i = 1)
  μ_i = 第 i 个分量的均值
  σ_i = 第 i 个分量的标准差
```

### 4.2 为什么是"混合"高斯？

**单高斯的局限**：

```
场景: 球到达岔路口

        /-- 路径A (向左)
  O ---
        \-- 路径B (向右)

真实分布:
  - 50% 概率在左边
  - 50% 概率在右边
  - 0% 概率在中间！

单高斯 N(μ, σ²) 只能表达单峰:

           *
          ***
         *****
        *******
    ----中间----

会把均值放在中间，但中间恰恰是概率为 0 的地方！
```

**混合高斯的优势**：

```
混合高斯 = π_1 * N(μ_1, σ_1²) + π_2 * N(μ_2, σ_2²)

    *               *
   ***             ***
  *****           *****
  左边峰          右边峰

可以表达"双峰"甚至"多峰"分布
每个峰代表一种可能的未来
```

### 4.3 直观对比

```
单高斯预测: "球下一帧大概在中间某处"
            -> 错！球不可能在墙中间

混合高斯预测: "球 50% 在左边，50% 在右边"
             -> 对！采样时会得到左或右，不会得到中间
```

---

## 5. MDN-RNN 完整架构

### 5.1 计算流程

```
输入: h_{t-1}, z_t, a_t
         |
         v
    +---------+
    |  LSTM   |  -> h_t (更新后的记忆)
    +---------+
         |
         v
    +---------+
    |   MDN   |  -> (π, μ, σ) for K 个高斯分量
    +---------+
         |
         v
    P(z_{t+1}) = Σ π_i * N(μ_i, σ_i²)
```

### 5.2 MDN 层的输出

```
对于 z 的每一维 (假设 z 是 32 维):
  - K 个权重 π_1, ..., π_K      (softmax 归一化)
  - K 个均值 μ_1, ..., μ_K
  - K 个标准差 σ_1, ..., σ_K    (exp 保证正数)

总输出维度: 32 * 3K 个参数
```

---

## 6. MDN 损失函数

### 6.1 负对数似然

```
我们有:
  - 真实值: z_{t+1} (一个具体的点)
  - 预测: P(z_{t+1}) = Σ π_i * N(μ_i, σ_i²) (一个分布)

损失函数:
  Loss = -log P(z_{t+1})
       = -log [Σ π_i * N(z_{t+1} | μ_i, σ_i²)]
```

### 6.2 直觉理解

```
如果真实的 z_{t+1} 落在预测分布的高概率区域:
  -> P(z_{t+1}) 大
  -> log P 大
  -> -log P 小
  -> Loss 小 (好!)

如果真实的 z_{t+1} 落在预测分布的低概率区域:
  -> P(z_{t+1}) 小
  -> log P 小 (负的很大)
  -> -log P 大
  -> Loss 大 (差!)
```

### 6.3 单个高斯的概率密度

```
N(z | μ, σ²) = (1 / sqrt(2πσ²)) * exp(-(z-μ)² / 2σ²)

对数形式:
log N(z | μ, σ²) = -0.5 * log(2π) - log(σ) - (z-μ)² / 2σ²
```

### 6.4 代码实现

```python
import torch
import torch.nn as nn

class MDN(nn.Module):
    def __init__(self, input_size, output_size, n_gaussians):
        super().__init__()
        self.n_gaussians = n_gaussians
        self.output_size = output_size

        # 输出: π, μ, σ for each gaussian
        self.pi = nn.Linear(input_size, n_gaussians)
        self.mu = nn.Linear(input_size, n_gaussians * output_size)
        self.sigma = nn.Linear(input_size, n_gaussians * output_size)

    def forward(self, x):
        pi = torch.softmax(self.pi(x), dim=-1)  # 权重归一化
        mu = self.mu(x)
        sigma = torch.exp(self.sigma(x))  # 保证正数
        return pi, mu, sigma


def mdn_loss(pi, mu, sigma, target):
    """
    计算 MDN 的负对数似然损失

    pi: (batch, n_gaussians) - 混合权重
    mu: (batch, n_gaussians * output_size) - 均值
    sigma: (batch, n_gaussians * output_size) - 标准差
    target: (batch, output_size) - 真实值
    """
    n_gaussians = pi.shape[-1]
    output_size = target.shape[-1]

    # 重塑 mu 和 sigma
    mu = mu.view(-1, n_gaussians, output_size)
    sigma = sigma.view(-1, n_gaussians, output_size)
    target = target.unsqueeze(1)  # (batch, 1, output_size)

    # 计算每个高斯分量的概率密度
    # N(z | μ, σ²) = (1/sqrt(2πσ²)) * exp(-(z-μ)²/2σ²)
    gaussian = torch.exp(-0.5 * ((target - mu) / sigma) ** 2)
    gaussian = gaussian / (sigma * math.sqrt(2 * math.pi))

    # 对所有输出维度求积 (假设维度独立)
    gaussian = torch.prod(gaussian, dim=-1)  # (batch, n_gaussians)

    # 混合: Σ π_i * N_i
    prob = torch.sum(pi * gaussian, dim=-1)  # (batch,)

    # 负对数似然
    loss = -torch.log(prob + 1e-8)  # 加小常数防止 log(0)
    return loss.mean()
```

---

## 7. 训练过程

### 7.1 数据准备

```
从环境收集轨迹:
  [(z_0, a_0), (z_1, a_1), (z_2, a_2), ...]

训练样本:
  输入: (z_t, a_t)
  标签: z_{t+1}
```

### 7.2 训练循环

```
for 每个时间步 t:
    1. 前向传播:
       (h_{t-1}, z_t, a_t) -> LSTM -> h_t
       h_t -> MDN -> (π, μ, σ)

    2. 计算损失:
       Loss = -log [Σ π_i * N(z_{t+1}^真实 | μ_i, σ_i²)]

    3. 反向传播:
       更新 LSTM 和 MDN 的参数
```

### 7.3 推理 (生成预测)

```
给定 (h_{t-1}, z_t, a_t):
    1. 得到分布参数 (π, μ, σ)
    2. 按权重 π 随机选择一个高斯分量 i
    3. 从 N(μ_i, σ_i²) 中采样得到 z_{t+1}
```

---

## 8. 与 World Models 的关系

### 8.1 M 组件在架构中的位置

```
World Models 架构:

观测图像
    |
    v
+--------+
|  VAE   |  V: 压缩感知
+--------+  图像 -> z
    |
    v
+----------+
| MDN-RNN  |  M: 理解规则
+----------+  (z_t, a_t, h_{t-1}) -> P(z_{t+1})
    |
    v
+--------+
|  线性   |  C: 决策
+--------+  (z_t, h_t) -> a_t
```

### 8.2 M 组件的作用

```
训练时:
  - 学习环境的动态规则
  - 从数据中提取"物理定律"

推理时 (梦境训练):
  - 生成想象的未来轨迹
  - 让 Controller 在想象中练习
  - 不需要真实环境交互
```

---

## 9. 总结

### 9.1 核心知识点

```
1. 为什么要 RNN?
   -> 记忆历史，解决非马尔可夫问题
   -> h_t 压缩了所有历史信息

2. 为什么用 LSTM?
   -> 门控机制，解决长期依赖
   -> 可以记住更久远的历史

3. 为什么要 MDN?
   -> 环境有随机性
   -> 同样输入可能有多种输出
   -> 混合高斯可以表达多模态分布

4. 为什么是"混合"高斯?
   -> 单高斯只能表达单峰
   -> 混合高斯可以表达多峰 (多种可能的未来)

5. MDN 损失函数?
   -> 负对数似然: -log P(z_真实)
   -> 让真实数据落在高概率区域
```

### 9.2 公式汇总

| 项目 | 公式 |
|:---|:---|
| RNN 更新 | `h_t = f(h_{t-1}, z_t, a_t)` |
| 混合高斯 | `P(z) = Σ π_i * N(μ_i, σ_i²)` |
| 高斯密度 | `N(z\|μ,σ²) = (1/√(2πσ²)) * exp(-(z-μ)²/2σ²)` |
| MDN 损失 | `Loss = -log [Σ π_i * N(z_真实 \| μ_i, σ_i²)]` |

### 9.3 RNN vs MDN-RNN

| | RNN | MDN-RNN |
|:---|:---|:---|
| 输出 | 确定的 z_{t+1} | 分布 P(z_{t+1}) |
| 表达能力 | 只能预测"平均"结果 | 可以表达多种可能 |
| 随机性 | 无法建模 | 显式建模 |
| 适用场景 | 确定性环境 | 随机性环境 |

---

## 10. 下一步

```
当前 [完成]
  +-- World Models 概念 (01)
  +-- VAE 数学原理 (02)
  +-- RNN/MDN 数学原理 (03)

下一步
  +-- C. 论文精读: 对照原文验证理解
  +-- A. 代码实现: 2_simple_world_model.py
  +-- D. 局限与发展: 为什么需要 Dreamer?
```

---

*文档生成时间: 2024-12-08*

*学习方法: 苏格拉底式对话*
